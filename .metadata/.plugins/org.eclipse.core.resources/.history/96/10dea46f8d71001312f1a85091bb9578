package cs.kuleuven.cp

/** 
 *  December 23rd, 2013
 */

import cs.kuleuven.java.mdl._
import cs.kuleuven.matrix._
import cs.kuleuven.constraints.IntWSum
import cs.kuleuven.java.mdl.BiclusterMDLScore
import cs.kuleuven.util.PotentialRegion
import oscar.cp.modeling._
import oscar.cp.core._
import breeze.stats.distributions.Bernoulli
import scala.util.continuations.{cps, cpsParam}

object biclusteringMDL  {
   
  def execute() = {
	
	  val delimiter = "\t"
	  val dupFile = "D:\\repos\\data\\biclusters\\8modules\\noise_10\\dup_bg_0.10_bic_0.10_8modules.txt"
	  val multiValuedFile = "D:\\repos\\data\\biclusters\\8modules\\noise_10\\bg_0.10_bic_0.10_8modules.txt"
	  //   
	  val dupMatrix = new DenseMatrix(dupFile, delimiter)
	  val mulMatrix = new DenseMatrix(multiValuedFile, delimiter)
	  //expMatrix.printMatrix
	  val nR = dupMatrix.rowSize
	  val nC = dupMatrix.colSize	  	  
	  //parameters
	  val rowThreshold = 25
	  val colThreshold = 25	    
	  //
	  val Rows = 0 until nR
	  val Cols	= 0 until nC	  	  
	  //decision variables
	  val cp = CPSolver()
	  val varRows =  Rows.map(i => CPVarBool(cp))
	  val varCols =  Cols.map(i => CPVarBool(cp))
	  val bestRows = Array.fill(nR)(0)
	  val bestCols = Array.fill(nC)(0)
	  // MDL
	  
	  //Randomizer
	  val rand = new scala.util.Random(0)
	  var bRegionBuilt = false
	  val pRegion = new PotentialRegion(dupMatrix, mulMatrix)
	  //optimization criterion
	  val biclusterArea = sum((0 until nR).map(r => varRows(r))) * sum((0 until nC).map(c => varCols(c))) 
	  
	  cp.maximize(biclusterArea)  subjectTo {
	    
		// 1.Noise constraints on rows
	    for(r <- Rows) {
	      val rWeight = (0 until nC).map(c => (100*dupMatrix.at(r,c) + rowThreshold - 100))	      
	      val coverageConstraint = new IntWSum(rWeight, varCols, 0, varRows(r))
	      cp.add(coverageConstraint)	      
	    }
	
	    //2.Noise constraints on columns
	    for(c <- Cols) {
	      //val colSum = sum((0 until nR).map(r => varRows(r) * (100*dupMatrix.at(r,c) + colThreshold - 100) ))
	      //cp.add(varCols(c) ==> (colSum >== 0))
	      val cWeight = (0 until nR).map(r => (100*dupMatrix.at(r,c) + colThreshold - 100))
	      val aux = new CPVarBool(cp)
	      val colNoiseConstraint = new IntWSum(cWeight, varRows, 0, aux)
	      cp.add(varCols(c) ==> aux)
	    }
	  }
	  
	  println("Constructing the potential region ...")
	  pRegion.buildPotentialRegion(cp, varRows, varCols, Array(1,2,3,4,5,6,7))	 
	  println("...done")
	  pRegion.printRegion
	  pRegion.printDensity
	  
	  cp.exploration {
	    
	    while(!allBounds(varCols) ) {
	      val unBoundedVars = (0 until varCols.length).filter(c => !varCols(c).isBound)
	      
	      val col = unBoundedVars.head
	      println("next: " + col + " - unBounded = " + unBoundedVars.length)
	      cp.branch {cp.post(varCols(col) == 0)} {cp.post(varCols(col) == 1)}
	    }
	     
	    printSolution(varRows, varCols)
	    //store the current best solution 
        Rows.foreach(r => bestRows(r) = varRows(r).value)
        Cols.foreach(c => bestCols(c) = varCols(c).value)
	    
	  } run(failureLimit = 100)
	  
	  for(i <- 0 until 2) {
	    println("Restart " + i + "th")
	  
	    cp.runSubjectTo(failureLimit = 100) {
	    	val outCols = pRegion.getOutsideCols
	       	for(c <- outCols) {
	    		cp.post(varCols(c) == 0)
	    	}
	    	
	    	val posCols = pRegion.getPosCols	    		  
	    	//val sortedDenCols = unBoundedCols.sortBy(c => pRegion.getColDensity(c))(Ordering[Double].reverse)	    	
	    	val highProbCols: scala.collection.mutable.Set[Int] = new scala.collection.mutable.HashSet()
	    	for(c <- posCols) {
	    	  val bern = new Bernoulli(pRegion.getColDensity(c))
	    	  if (bern.sample)
	    	    highProbCols += c
	    	}
	    	
	    	println("High prob cols: " + highProbCols)
	    	for(c <- highProbCols) { 
	    	  cp.post(varCols(c) == 1)
	    	  //cp.branch {cp.post(varCols(c) == 1)} {cp.post(varCols(c) == 1)}	    	  
	    	}
		  }
	  }

  }
  
  
    
    def main(args: Array[String]) {
        //print("hello")
        execute()
    }
    
    
    def printSolution(rows: IndexedSeq[CPVarBool], cols:IndexedSeq[CPVarBool]) = {
	    val selectedCols = (0 until cols.size).filter(c => cols(c).getValue == 1)
	    val selectedRows = (0 until rows.size).filter(r => rows(r).getValue == 1)
	    println()
	    println("Cols = " + selectedCols + " [" + selectedCols.size + "/" + cols.size + "]")
	    println("Rows = " + selectedRows + " [" + selectedRows.size + "/" + rows.size + "]")	    
	}

    def test() = {
        val delimiter = "\t"  
        //val filename = "D:\\repos\\data\\biclusters\\test_tdb.txt"      
        val filename = "D:\\repos\\data\\biclusters\\8modules\\noise_10\\bg_0.10_bic_0.10_8modules.txt"  
        val matrix = new DenseMatrix(filename, delimiter) 
        var mdl = new BiclusterMDLScore() 
        mdl.setTdb(matrix);
        var r = mdl.getTdb().rowSize                      //> r  : Int = 3
        val bicRows = (1499 until 1800).map(x => x:Integer).toArray//Array(0,1,2).map(x => x: Integer)
        val bicCols = (0 until 10).map(x => x:Integer).toArray//Array(0,1,2).map(x => x: Integer)
        //val bicRows = (0 until 200).map(x => x:Integer).toArray//Array(0,1,2).map(x => x: Integer)
        //val bicCols = (0 until 100).map(x => x:Integer).toArray//Array(0,1,2).map(x => x: Integer)
        //val bicRows = Array(1,2,3).map(x => x: Integer)
        //val bicCols = Array(0,1,2).map(x => x: Integer)
        val query = Array(1, 3, 5)
        
        //var t = mdl.buildDBDensityMap(); 
        mdl.setBicIndexes(bicRows, bicCols)
        
        //mdl.getBicRowDefaults()
        //mdl.buildBicDensityMaps()
        mdl.printBicDensityMaps()
        println("model length = " + mdl.getModelLength())
        println("data length = " + mdl.getDataLength())
        println("MDL score = " + mdl.getMDLScore())
        val c = mdl.getNextCompressedCol()
        println("Next column: " + c)
    }
     
}